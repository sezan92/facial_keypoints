{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keypoint Detecton- GradCam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this blog, I am showing, how can we ensure , if our model is truly learning features from the image. For this , I am using - a bit modified- *** GradCam ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradcam for dummies- like me "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For people like me , In simple terms, Gradcam is some lines of codes to show which features or parts of the images **activates** to a particular layer when you feed into it. The most famouse example is this following image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![gcam_cat](newgcam_heatmap_overlaid_283_cat_dog.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the image shows, the parts of the image, which gets activated when it classifies \"cat\". [link](https://arxiv.org/abs/1610.02391)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ok, lets get it done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os.path as osp\n",
    "\n",
    "import click\n",
    "import cv2\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models, transforms\n",
    "\n",
    "from grad_cam import (\n",
    "    GradCAM,\n",
    "    GuidedBackPropagation\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    _,ret = cv2.imencode('.jpg', img) \n",
    "    i = IPython.display.Image(data=ret)\n",
    "    IPython.display.display(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_device(cuda):\n",
    "    cuda = cuda and torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "    if cuda:\n",
    "        current_device = torch.cuda.current_device()\n",
    "        print(\"Device:\", torch.cuda.get_device_name(current_device))\n",
    "    else:\n",
    "        print(\"Device: CPU\")\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(image_paths):\n",
    "    images = []\n",
    "    raw_images = []\n",
    "    print(\"Images:\")\n",
    "    for i, image_path in enumerate(image_paths):\n",
    "        print(\"\\t#{}: {}\".format(i, image_path))\n",
    "        image, raw_image = preprocess(image_path)\n",
    "        images.append(image)\n",
    "        raw_images.append(raw_image)\n",
    "    return images, raw_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classtable():\n",
    "    classes = []\n",
    "    with open(\"samples/synset_words.txt\") as lines:\n",
    "        for line in lines:\n",
    "            line = line.strip().split(\" \", 1)[1]\n",
    "            line = line.split(\", \", 1)[0].replace(\" \", \"_\")\n",
    "            classes.append(line)\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image_path):\n",
    "    raw_image = cv2.imread(image_path)\n",
    "    raw_image = cv2.resize(raw_image, (9))\n",
    "    image = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )(raw_image[..., ::-1].copy())\n",
    "    return image, raw_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_gradient(filename, gradient):\n",
    "    gradient = gradient.cpu().numpy().transpose(1, 2, 0)\n",
    "    gradient -= gradient.min()\n",
    "    gradient /= gradient.max()\n",
    "    gradient *= 255.0\n",
    "    imshow(gradient)\n",
    "    cv2.imwrite(filename, np.uint8(gradient))\n",
    "\n",
    "\n",
    "def save_gradcam(filename, gcam, raw_image, paper_cmap=False):\n",
    "    gcam = gcam.cpu().numpy()\n",
    "    cmap = cm.jet_r(gcam)[..., :3] * 255.0\n",
    "    if paper_cmap:\n",
    "        alpha = gcam[..., None]\n",
    "        gcam = alpha * cmap + (1 - alpha) * raw_image\n",
    "    else:\n",
    "        gcam = (cmap.astype(np.float) + raw_image.astype(np.float)) / 2\n",
    "    imshow(gcam)\n",
    "    cv2.imwrite(filename, np.uint8(gcam))\n",
    "\n",
    "\n",
    "def save_sensitivity(filename, maps):\n",
    "    maps = maps.cpu().numpy()\n",
    "    scale = max(maps[maps > 0].max(), -maps[maps <= 0].min())\n",
    "    maps = maps / scale * 0.5\n",
    "    maps += 0.5\n",
    "    maps = cm.bwr_r(maps)[..., :3]\n",
    "    maps = np.uint8(maps * 255.0)\n",
    "    maps = cv2.resize(maps, (224, 224), interpolation=cv2.INTER_NEAREST)\n",
    "    cv2.imwrite(filename, maps)\n",
    "    imshow(maps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths=[\"../image.npy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir=\"output_dir/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SezanNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SezanNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(4, 4),stride=2) ## 32x47x47\n",
    "        self.dropout=nn.Dropout()\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(4, 4),stride=2) # 64x22x22\n",
    "        self.conv3 = nn.Conv2d(in_channels=64,out_channels=128,kernel_size=(3,3),stride=2) # 128x10x10\n",
    "        self.conv4 = nn.Conv2d(in_channels=128,out_channels=256,kernel_size=(1,1),stride=2) # 256x5x5\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(in_features=256*5*5,out_features=30)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.dropout(self.relu(self.conv1(x)))\n",
    "        x = self.dropout(self.relu(self.conv2(x)))\n",
    "        x = self.dropout(self.relu(self.conv3(x)))\n",
    "        x = self.dropout(self.relu(self.conv4(x)))\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=SezanNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"../network_state_dict.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_image = np.load(\"../image.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=raw_image.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image.reshape(-1,96,96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 96, 96)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.from_numpy(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[142., 142., 142.,  ...,  24.,  24.,  24.],\n",
       "         [142., 142., 142.,  ...,  24.,  24.,  24.],\n",
       "         [143., 142., 142.,  ...,  24.,  24.,  23.],\n",
       "         ...,\n",
       "         [128., 127., 128.,  ...,  66.,  63.,  60.],\n",
       "         [128., 127., 128.,  ...,  64.,  61.,  58.],\n",
       "         [127., 128., 128.,  ...,  62.,  60.,  58.]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=images.reshape(-1,1,96,96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.5569, 0.5569, 0.5569,  ..., 0.0941, 0.0941, 0.0941],\n",
       "          [0.5569, 0.5569, 0.5569,  ..., 0.0941, 0.0941, 0.0941],\n",
       "          [0.5608, 0.5569, 0.5569,  ..., 0.0941, 0.0941, 0.0902],\n",
       "          ...,\n",
       "          [0.5020, 0.4980, 0.5020,  ..., 0.2588, 0.2471, 0.2353],\n",
       "          [0.5020, 0.4980, 0.5020,  ..., 0.2510, 0.2392, 0.2275],\n",
       "          [0.4980, 0.5020, 0.5020,  ..., 0.2431, 0.2353, 0.2275]]]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "device = get_device(cuda)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Images\n",
    "\n",
    "images = torch.stack(tuple(images)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=images.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanilla Backpropagation:\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Common usage:\n",
    "1. Wrap your model with visualization classes defined in grad_cam.py\n",
    "2. Run forward() with images\n",
    "3. Run backward() with a list of specific classes\n",
    "4. Run generate() to export results\n",
    "\"\"\"\n",
    "\n",
    "# =========================================================================\n",
    "print(\"Vanilla Backpropagation:\")\n",
    "\n",
    "bp = BackPropagation(model=model)\n",
    "keypoints = bp.forward(images)  # sorted"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bp.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3991, -0.1617, -0.3830, -0.2123,  0.2350, -0.2453,  0.5630, -0.2603,\n",
       "         -0.2257, -0.1832, -0.5584, -0.1751,  0.1013, -0.3660,  0.7163, -0.4049,\n",
       "         -0.2087, -0.3082, -0.7137, -0.2871, -0.0958,  0.3878,  0.4939,  0.5568,\n",
       "         -0.3131,  0.6424,  0.0499,  0.6254, -0.0738,  0.7241]],\n",
       "       grad_fn=<ThAddmmBackward>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(topk):\n",
    "    bp.backward(ids=keypoints)\n",
    "    gradients = bp.generate()\n",
    "\n",
    "    # Save results as image files\n",
    "    for j in range(len(images)):\n",
    "        \n",
    "        save_gradient(\n",
    "            filename=osp.join(\n",
    "                output_dir,\n",
    "                \"{}-{}.png\".format(j,i)\n",
    "            ),\n",
    "            gradient=gradients[j],\n",
    "        )\n",
    "\n",
    "# Remove all the hook function in the \"model\"\n",
    "bp.remove_hook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "conv1\n",
      "dropout\n",
      "conv2\n",
      "conv3\n",
      "conv4\n",
      "relu\n",
      "fc1\n"
     ]
    }
   ],
   "source": [
    "for name,module in model.named_modules():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layer=\"conv1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad-CAM/Guided Backpropagation/Guided Grad-CAM:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Grad-CAM/Guided Backpropagation/Guided Grad-CAM:\")\n",
    "\n",
    "gcam = GradCAM(model=model)\n",
    "_ = gcam.forward(images)\n",
    "\n",
    "gbp = GuidedBackPropagation(model=model)\n",
    "_ = gbp.forward(images)\n",
    "\n",
    "for i in range(topk):\n",
    "    # Guided Backpropagation\n",
    "    gbp.backward(keypoints)\n",
    "    gradients = gbp.generate()\n",
    "\n",
    "    # Grad-CAM\n",
    "    gcam.backward(keypoints)\n",
    "    regions = gcam.generate(target_layer=target_layer)\n",
    "\n",
    "    for j in range(len(images)):\n",
    "        \n",
    "\n",
    "        # Guided Backpropagation\n",
    "        save_gradient(\n",
    "            filename=osp.join(\n",
    "                output_dir,\n",
    "                \"{}-{}-guided.png\".format(j,i),\n",
    "            ),\n",
    "            gradient=gradients[j],\n",
    "        )\n",
    "\n",
    "        # Grad-CAM\n",
    "        save_gradcam(\n",
    "            filename=osp.join(\n",
    "                output_dir,\n",
    "                \"{}-{}-gradcam.png\".format(\n",
    "                    j, i                ),\n",
    "            ),\n",
    "            gcam=regions[j, 0],\n",
    "            raw_image=raw_image\n",
    "        )\n",
    "\n",
    "        # Guided Grad-CAM\n",
    "        save_gradient(\n",
    "            filename=osp.join(\n",
    "                output_dir,\n",
    "                \"{}-{}-guided_gradcam.png\".format(\n",
    "                    j,i\n",
    "                ),\n",
    "            ),\n",
    "            gradient=torch.mul(regions, gradients)[j],\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
