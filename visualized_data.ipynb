{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualize "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook , I  am loading the data and visualizing it ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pickle.load(open(\"train_images.pkl\",\"rb\"))\n",
    "y_train = pickle.load(open(\"train_labels.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image= X_train[1717]\n",
    "\n",
    "label= y_train[1717]\n",
    "\n",
    "label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function for visualize image with label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(image,label):\n",
    "    x,y=[],[]\n",
    "    for i in range(label.shape[0]):\n",
    "        if (i+1)%2==1:\n",
    "            x.append(label[i])\n",
    "        else:\n",
    "            y.append(label[i])\n",
    "\n",
    "\n",
    "    plt.imshow(image.reshape(96,96),cmap=\"gray\")\n",
    "    plt.scatter(x,y,c=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(image,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"image.npy\",image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"sample.jpg\",image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "# tranforms\n",
    "\n",
    "class Normalize(object):\n",
    "    \"\"\"Convert a color image to grayscale and normalize the color range to [0,1].\"\"\"        \n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, key_pts = sample['image'], sample['keypoints']\n",
    "        \n",
    "        image_copy = np.copy(image)\n",
    "        key_pts_copy = np.copy(key_pts)\n",
    "\n",
    "        # convert image to grayscale\n",
    "        image_copy=  image_copy / 255.0\n",
    "            \n",
    "        \n",
    "        # scale keypoints to be centered around 0 with a range of [-1, 1]\n",
    "        # mean = 100, sqrt = 50, so, pts should be (pts - 100)/50\n",
    "#         key_pts_copy = (key_pts_copy - 100)/50.0\n",
    "        key_pts_copy = (key_pts_copy - 48) / 48.0 # NaimishNet paper p3 Data Pre-processing\n",
    "\n",
    "        return {'image': image_copy, 'keypoints': key_pts_copy}\n",
    "\n",
    "\n",
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, key_pts = sample['image'], sample['keypoints']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "\n",
    "        img = cv2.resize(image, (new_w, new_h))\n",
    "        \n",
    "        # scale the pts, too\n",
    "        key_pts = key_pts * [new_w / w, new_h / h]\n",
    "\n",
    "        return {'image': img, 'keypoints': key_pts}\n",
    "\n",
    "\n",
    "class RandomCrop(object):\n",
    "    \"\"\"Crop randomly the image in a sample.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, key_pts = sample['image'], sample['keypoints']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        new_h, new_w = self.output_size\n",
    "        print(h,w)\n",
    "        top = np.random.randint(0, h - new_h)\n",
    "        left = np.random.randint(0, w - new_w)\n",
    "\n",
    "        image = image[top: top + new_h,\n",
    "                      left: left + new_w]\n",
    "\n",
    "        key_pts = key_pts - [left, top]\n",
    "\n",
    "        return {'image': image, 'keypoints': key_pts}\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, key_pts = sample['image'], sample['keypoints']\n",
    "         \n",
    "        # if image has no grayscale color channel, add one\n",
    "        if(len(image.shape) == 2):\n",
    "            # add that third color dim\n",
    "            image = image.reshape(image.shape[0], image.shape[1], 1)\n",
    "            \n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        \n",
    "        return {'image': torch.from_numpy(image),\n",
    "                'keypoints': torch.from_numpy(key_pts)}\n",
    "\n",
    "class FacialKeypointsDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, image_pickle_file,label_pickle_file, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.images= pickle.load(open(image_pickle_file,\"rb\"))\n",
    "        self.labels= pickle.load(open(label_pickle_file,\"rb\"))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if True:\n",
    "            image=self.images[idx]\n",
    "            keypoints=self.labels[idx]\n",
    "            sample = {'image': image, 'keypoints': keypoints}\n",
    "\n",
    "            if self.transform:\n",
    "                sample = self.transform(sample)\n",
    "\n",
    "            return sample\n",
    "        \n",
    "            \n",
    "            #print(e)\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "# Perform data augmentation on train dataset by first scaling and then random cropping\n",
    "train_data_transform = transforms.Compose([Normalize(), \\\n",
    "                                           ToTensor()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FacialKeypointsDataset(\"train_images.pkl\",\"train_labels.pkl\",transform=train_data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=sample[\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=sample[\"keypoints\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image.reshape(96,96),cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints=sample[\"keypoints\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
